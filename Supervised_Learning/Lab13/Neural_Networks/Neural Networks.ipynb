{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=\"6\">Neural Networks - The parameters and GridSearch</font></b><br><br>\n",
    "\n",
    "In this notebook we are going to check some of the most important parameters that can influence the performance of a neural network.\n",
    "\n",
    "# <font color='#BFD72F'>Contents</font> <a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "* [1. The needed steps](#import)\n",
    "* [2. Neural Networks](#nn)\n",
    "    * [2.1. The hidden layer size - Number of hidden layers and units](#hidden)\n",
    "    * [2.2. The activation function](#activation)\n",
    "    * [2.3. The solver](#solver)\n",
    "    * [2.4. The learning rate initialization](#lr_init)\n",
    "    * [2.5. The learning rate](#lr)\n",
    "    * [2.6. The batch size](#batch)\n",
    "    * [2.7. The maximum iterations](#max_iter)\n",
    "    * [2.8. Other parameters](#other)\n",
    "* [3. The GridSearch](#gridsearch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The needed steps <a class=\"anchor\" id=\"1st-bullet\"></a>\n",
    "[Back to Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"2nd-bullet\">\n",
    "\n",
    "### 1.1. Import the needed libraries\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 1`__ Import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"3rd-bullet\">\n",
    "\n",
    "### 1.2. Import the dataset\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 1`__ - Import the dataset __diabetes.csv__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv(r'data\\diabetes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2`__ - Define the independent variables as __X__ and the dependent variable as __y__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes.iloc[:,:-1]\n",
    "y = diabetes.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 3`__ - Create a function named __avg_score__ that will return the average score value for the train and the validation set by applying a model, besides that it should also count the amount of time the model takes to fit, and the number of iterations needed. The model should be received by the function as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(model):\n",
    "    # apply kfold\n",
    "    kf = KFold(n_splits=10)\n",
    "    # create lists to store the results from the different models \n",
    "    score_train = []\n",
    "    score_val = []\n",
    "    timer = []\n",
    "    n_iter = []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        # get the indexes of the observations assigned for each partition\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        # start counting time\n",
    "        begin = time.perf_counter()\n",
    "        # fit the model to the data\n",
    "        model.fit(X_train, y_train)\n",
    "        # finish counting time\n",
    "        end = time.perf_counter()\n",
    "        # check the mean accuracy for the train\n",
    "        value_train = model.score(X_train, y_train)\n",
    "        # check the mean accuracy for the validation\n",
    "        value_val = model.score(X_val, y_val)\n",
    "        # append the accuracies, the time and the number of iterations in the corresponding list\n",
    "        score_train.append(value_train)\n",
    "        score_val.append(value_val)\n",
    "        timer.append(end-begin)\n",
    "        n_iter.append(model.n_iter_)\n",
    "    # calculate the average and the std for each measure (accuracy, time and number of iterations)\n",
    "    avg_time = round(np.mean(timer),3)\n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_val = round(np.mean(score_val),3)\n",
    "    std_time = round(np.std(timer),2)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_val = round(np.std(score_val),2)\n",
    "    avg_iter = round(np.mean(n_iter),1)\n",
    "    std_iter = round(np.std(n_iter),1)\n",
    "    \n",
    "    return str(avg_time) + '+/-' + str(std_time), str(avg_train) + '+/-' + str(std_train),\\\n",
    "str(avg_val) + '+/-' + str(std_val), str(avg_iter) + '+/-' + str(std_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 4`__ - Create a function named __show_results__ that will return the average score for the train and validation\n",
    " dataset (returned from the function __avg_score__) for several given models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(df, *args):\n",
    "    \"\"\"\n",
    "    Receive an empty dataframe and the different models and call the function avg_score\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # for each model passed as argument\n",
    "    for arg in args:\n",
    "        # obtain the results provided by avg_score\n",
    "        time, avg_train, avg_val, avg_iter = avg_score(arg)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = time, avg_train, avg_val, avg_iter\n",
    "        count+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Neural Networks <a class=\"anchor\" id=\"nn\"></a>\n",
    "[Back to Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 5`__ - Create an instance of MLPClassifier with the default parameters and name it as __model__. Check the results using the above created functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Raw</th>\n",
       "      <td>1.187+/-0.49</td>\n",
       "      <td>0.752+/-0.02</td>\n",
       "      <td>0.712+/-0.06</td>\n",
       "      <td>123.1+/-38.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time         Train    Validation    Iterations\n",
       "Raw  1.187+/-0.49  0.752+/-0.02  0.712+/-0.06  123.1+/-38.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier()\n",
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'Iterations'], index = ['Raw'])\n",
    "show_results(df, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"hidden\">\n",
    "\n",
    "### 2.1. The hidden layer size - Number of hidden layers and neurons (default = (100,))\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The number of hidden layers__<br>\n",
    "-\tIncrease the number of hidden layers might improve the accuracy or might not, it depend on the complexity of the problem\n",
    "-\tIncrease the number of hidden layers more than the sufficient ones will cause overfit on training set and the decrease of the accuracy in the test set\n",
    "\n",
    "__The number of hidden units__ <br>\n",
    "-\tUsing too few neurons in hidden layers will result in underfitting\n",
    "-\tUsing too many neurons in the hidden layer may result in overfitting and increase the time it takes to train the neural network\n",
    "\n",
    "The aim is to keep a good trade-off between the simplicity of the model and the performance accuracy! <br>\n",
    "\n",
    "__Some rule of thumbs:__\n",
    "-\tThe number of hidden neurons should be between the size of the input layer and the size of the output layer\n",
    "-\tThe number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer\n",
    "-\tThe number of hidden neurons should be less than twice the size of the input layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/neuralnetwork.gif\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 6`__ - Create an MLPClassifier with one hidden layer and one neuron and name it __model_simple__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple = MLPClassifier(hidden_layer_sizes=(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 7`__ - Create an MLPClassifier with one hidden layer and 10 neurons and name it __model_medium__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_medium = MLPClassifier(hidden_layer_sizes=(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 8`__ - Create an MLPClassifier with four hidden layers and 100 neurons each and name it __model_complex__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complex = MLPClassifier(hidden_layer_sizes = (100,100,100,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 9`__ - Check the mean accuracy of each model by calling the function _show_results_ and pass as arguments the dataset and the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Simple</th>\n",
       "      <td>0.6+/-0.15</td>\n",
       "      <td>0.622+/-0.09</td>\n",
       "      <td>0.604+/-0.13</td>\n",
       "      <td>181.3+/-46.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medium</th>\n",
       "      <td>0.709+/-0.27</td>\n",
       "      <td>0.687+/-0.02</td>\n",
       "      <td>0.682+/-0.06</td>\n",
       "      <td>181.3+/-56.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Complex</th>\n",
       "      <td>4.096+/-1.44</td>\n",
       "      <td>0.81+/-0.04</td>\n",
       "      <td>0.708+/-0.06</td>\n",
       "      <td>108.9+/-41.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Time         Train    Validation    Iterations\n",
       "Simple     0.6+/-0.15  0.622+/-0.09  0.604+/-0.13  181.3+/-46.7\n",
       "Medium   0.709+/-0.27  0.687+/-0.02  0.682+/-0.06  181.3+/-56.1\n",
       "Complex  4.096+/-1.44   0.81+/-0.04  0.708+/-0.06  108.9+/-41.7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'Iterations'], index = ['Simple','Medium','Complex'])\n",
    "show_results(df, model_simple, model_medium, model_complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the results may differ in different runs, we probably will get the following conclusions:\n",
    "- The more complex the model, the higher the running time;\n",
    "- We can have a boost on the performance on our model when we adjust rightly the complexity of it - too simple leads to underfitting, and too complex can lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"activation\">\n",
    "    \n",
    "### 2.2. The activation function (default = 'relu')\n",
    "    \n",
    "</a>\n",
    "\n",
    "Check this link for more information regarding the advantages and disadvantages of different activation functions: <br>https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/activation.png\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 10`__ - Create an instance of MLPClassifier, define the activation as __relu__ and name it as __model_relu__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu = MLPClassifier(activation = 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - __Advantages:__\n",
    "     - Computationally efficient - allows the network to converge very quickly.\n",
    "     - Nonlinear - Although it looks like a linear function, ReLU has a derivative function and allows for backpropagation\n",
    " - __Disadvantages:__\n",
    "     - The **dying ReLU problem** - When inputs approach zero, or are negative, the gradient of the function becomes zero and the network cannot perform backpropagation and cannot learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 11`__ - Create an instance of MLPClassifier, define the activation as __logistic__ and name it as __model_logistic__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = MLPClassifier(activation = 'logistic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - __Advantages:__\n",
    "     - Smooth gradient, preventing “jumps” in output values.\n",
    "     - Output values bound between 0 and 1, normalizing the output of each neuron.\n",
    " - __Disadvantages:__\n",
    "     - Vanishing gradient—for very high or very low values of X, there is almost no change to the prediction, causing a vanishing gradient problem. This can result in the network refusing to learn further, or have slow convergence.\n",
    "     - Computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 12`__ - Create an instance of MLPClassifier, define the activation as __tanh__ and name it as __model_tanh__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tanh = MLPClassifier(activation = 'tanh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - __Advantages:__\n",
    "     - Zero centered - making it easier to model inputs that have strongly negative, neutral and strongly positive values. Otherwise like sigmoid function. <br>\n",
    " - __Disadvantages:__\n",
    "     - Like the logistic function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 13`__ - Check the mean accuracy of each model by calling the function _show_results_ and pass as arguments the dataset and the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>1.306+/-0.37</td>\n",
       "      <td>0.735+/-0.02</td>\n",
       "      <td>0.681+/-0.04</td>\n",
       "      <td>106.8+/-35.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic</th>\n",
       "      <td>1.856+/-0.24</td>\n",
       "      <td>0.783+/-0.01</td>\n",
       "      <td>0.721+/-0.04</td>\n",
       "      <td>200.0+/-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>2.616+/-0.49</td>\n",
       "      <td>0.815+/-0.01</td>\n",
       "      <td>0.711+/-0.06</td>\n",
       "      <td>200.0+/-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time         Train    Validation    Iterations\n",
       "relu      1.306+/-0.37  0.735+/-0.02  0.681+/-0.04  106.8+/-35.6\n",
       "logistic  1.856+/-0.24  0.783+/-0.01  0.721+/-0.04   200.0+/-0.0\n",
       "tanh      2.616+/-0.49  0.815+/-0.01  0.711+/-0.06   200.0+/-0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'Iterations'], index = ['relu','logistic','tanh'])\n",
    "show_results(df, model_relu, model_logistic, model_tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the results, we can identify some evidences:\n",
    "- Relu tends to be faster than logistic or tanh.\n",
    "- Sigmoid functions and their combinations (such as tanh) generally work better in the case of classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"solver\">\n",
    "    \n",
    "### 2.3. The solver (default = 'adam')\n",
    "\n",
    "    \n",
    "</a>\n",
    "For more information check this paper: <br>   \n",
    "\n",
    "http://www.robotics.stanford.edu/~ang/papers/icml11-OptimizationForDeepLearning.pdf <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 14`__ - Create an instance of MLPClassifier, define the solver as __sgd__ and name ir as __model_sgd__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd = MLPClassifier(solver = 'sgd')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use__\n",
    "- If generalization is more important than time processing - Some recent papers observe that the solutions found by adaptive methods generalize worse (often significantly worse) than SGD, even when these solutions have better training performance.\n",
    "(https://papers.nips.cc/paper/7003-the-marginal-value-of-adaptive-gradient-methods-in-machine-learning.pdf)\n",
    "\n",
    "__Notes__\n",
    "- While Gradient Descent use the whole training data to do a single update, in SGD a random data point of the training data to update the parameters - SGD is faster than GD.\n",
    "- It uses a **common learning rate** for all parameters, contrarialy to what happen in Adam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 15`__ - Create an instance of MLPClassifier, define the solver as __adam__ and name it as __model_adam__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adam = MLPClassifier(solver = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__When to use__ <br>\n",
    "- It achieves good results fast - good for complex models, if processing time is an issue.\n",
    "\n",
    "__Notes__ <br>\n",
    "- It computes individual adaptive learning rates for different parameters\n",
    "- Adam combines the advantages of RMSProp and AdaGrad <br>\n",
    "(For more about Adam, check this: https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c)\n",
    "- Recent research papers have noted that it can fail to converge to an optimal solution under specific settings.\n",
    "(The paper https://arxiv.org/pdf/1712.07628.pdf demonstrates that adaptive optimization techniques such as Adam generalize poorly compared to SGD)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 16`__ - Check the mean accuracy of each model by calling the function _show_results_ and pass as arguments the dataset and the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.482+/-0.19</td>\n",
       "      <td>0.713+/-0.02</td>\n",
       "      <td>0.676+/-0.05</td>\n",
       "      <td>51.6+/-16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adam</th>\n",
       "      <td>1.288+/-0.55</td>\n",
       "      <td>0.752+/-0.02</td>\n",
       "      <td>0.693+/-0.05</td>\n",
       "      <td>117.4+/-33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Time         Train    Validation    Iterations\n",
       "sgd   0.482+/-0.19  0.713+/-0.02  0.676+/-0.05   51.6+/-16.4\n",
       "adam  1.288+/-0.55  0.752+/-0.02  0.693+/-0.05  117.4+/-33.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'Iterations'], index = ['sgd','adam'])\n",
    "show_results(df, model_sgd, model_adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn, the number of iterations for __sgd__ and __adam__ correspond to the number of epochs (an epoch consists of one full cycle through the training data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/optimizers.gif\" width=\"350px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"lr_init\">\n",
    "\n",
    "### 2.4. The learning rate initialization - only for sgd and adam (default = 0.001)\n",
    "    \n",
    "</a>\n",
    "\n",
    "The learning rate is one of the most important hyper-parameters to tune for training deep neural networks:\n",
    "\n",
    "__Small LR__\n",
    "- If the learning rate is small, then training is more reliable, but optimization will take a lot of time because steps towards the minimum of the loss function are tiny - a smaller learning rate may allow the model to learn a more optimal or even globally optimal set of weights but may take significantly longer to train.\n",
    "- A learning rate that is too small may never converge or may get stuck on a suboptimal solution.\n",
    "\n",
    "__Big LR__\n",
    "- If the learning rate is high, then training may not converge or even diverge. Weight changes can be so big that the optimizer overshoots the minimum and makes the loss worse - a large learning rate allows the model to learn faster, at the cost of arriving on a sub-optimal final set of weights.\n",
    "\n",
    "\n",
    "The training should start from a relatively large learning rate because, in the beginning, random weights are far from optimal, and then the learning rate can decrease during training to allow more fine-grained weight updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 18`__ - Create an instance of MLPClassifier, define the solver as __sgd__, the learning_rate_init as __0.5__ and name it as __model_lr_big__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_big = MLPClassifier(solver = 'sgd', learning_rate_init = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 19`__ - Create an instance of MLPClassifier, define the solver as __sgd__, the learning_rate_init as __0.001__ and name it as __model_lr_medium__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_medium = MLPClassifier(solver = 'sgd', learning_rate_init = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 20`__ - Create an instance of MLPClassifier, define the solver as __sgd__, the learning_rate_init as __0.000001__ and name it as __model_lr_small__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_small = MLPClassifier(solver = 'sgd', learning_rate_init = 0.000001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 21`__ - Check the mean accuracy of each model by calling the function _show_results_ and pass as arguments the dataset and the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>0.122+/-0.02</td>\n",
       "      <td>0.651+/-0.01</td>\n",
       "      <td>0.651+/-0.07</td>\n",
       "      <td>12.0+/-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medium</th>\n",
       "      <td>0.951+/-0.61</td>\n",
       "      <td>0.731+/-0.01</td>\n",
       "      <td>0.695+/-0.06</td>\n",
       "      <td>74.8+/-33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>2.304+/-0.57</td>\n",
       "      <td>0.599+/-0.06</td>\n",
       "      <td>0.579+/-0.08</td>\n",
       "      <td>200.0+/-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time         Train    Validation   Iterations\n",
       "big     0.122+/-0.02  0.651+/-0.01  0.651+/-0.07   12.0+/-0.0\n",
       "medium  0.951+/-0.61  0.731+/-0.01  0.695+/-0.06  74.8+/-33.0\n",
       "small   2.304+/-0.57  0.599+/-0.06  0.579+/-0.08  200.0+/-0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'Iterations'], index = ['big','medium','small'])\n",
    "show_results(df, model_lr_big, model_lr_medium, model_lr_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"lr\">\n",
    "\n",
    "### 2.5. The learning rate - Only for sgd (default = 'constant')\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 22`__ - Create an instance of MLPClassifier, define the solver as __sgd__, the learning_rate as __constant__ and name it as __model_constant__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_constant = MLPClassifier(solver = 'sgd', learning_rate = 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definition__<br>\n",
    "If the learning rate is constant, as the name says, the learning rate will always remain equal to the initial learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 23`__ - Create an instance of MLPClassifier, define the solver as __sgd__, the learning_rate as __invscaling__ and name it as __model_invscaling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_invscaling = MLPClassifier(solver = 'sgd', learning_rate = 'invscaling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definition__<br>\n",
    "If the learning rate is invscaling, it gradually decreases the learning rate at each time step ‘t’ using an inverse scaling exponent of ‘power_t’. <br><br>\n",
    "$$effective\\; learning\\; rate = \\frac{learning\\_rate\\_init}{t\\;^{power\\_t}}$$ <br>\n",
    "The __power_t__ (default = 0.5) is another parameter that you can change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 24`__ - Create an instance of MLPClassifier, define the solver as __sgd__, the learning_rate as __adaptive__ and name it as __model_adaptive__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adaptive = MLPClassifier(solver = 'sgd', learning_rate = 'adaptive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Definition__ <br>\n",
    "If the learning rate is adaptive, then it keeps the learning rate constant to ‘learning_rate_init’ as long as training loss keeps decreasing. <br><br>\n",
    "Each time two consecutive epochs fail to decrease training loss by at least __tol__ (another parameter that you can change), or fail to increase validation score by at least __tol__ if __early_stopping__ (another parameter that you can change) is on, the current learning rate is divided by 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 25`__ - Check the mean accuracy of each model by calling the function _show_results_ and pass as arguments the dataset and the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>constant</th>\n",
       "      <td>0.801+/-0.28</td>\n",
       "      <td>0.723+/-0.02</td>\n",
       "      <td>0.671+/-0.06</td>\n",
       "      <td>61.8+/-13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invscaling</th>\n",
       "      <td>0.822+/-1.07</td>\n",
       "      <td>0.633+/-0.07</td>\n",
       "      <td>0.637+/-0.07</td>\n",
       "      <td>68.6+/-86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive</th>\n",
       "      <td>1.746+/-0.72</td>\n",
       "      <td>0.746+/-0.01</td>\n",
       "      <td>0.71+/-0.06</td>\n",
       "      <td>171.9+/-23.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Time         Train    Validation    Iterations\n",
       "constant    0.801+/-0.28  0.723+/-0.02  0.671+/-0.06   61.8+/-13.9\n",
       "invscaling  0.822+/-1.07  0.633+/-0.07  0.637+/-0.07   68.6+/-86.0\n",
       "adaptive    1.746+/-0.72  0.746+/-0.01   0.71+/-0.06  171.9+/-23.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'Iterations'], index = ['constant','invscaling','adaptive'])\n",
    "show_results(df, model_constant, model_invscaling, model_adaptive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"batch\">\n",
    "\n",
    "### 2.6. The batch size (default = min(200, n_samples))\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch size can affect significantly the performance and the speed of your training. What happens when you put a batch through your network is that you average the gradients. <br>\n",
    "\n",
    "__Small batch size__\n",
    "- The lower the batch size, the higher the probability of your estimate being less accurate, since the networks weights can \"jump\" around if your data is noisy, and it might be unable to learn, or it converges very slow. Besides that, the computation time is going to increase.\n",
    "- It can be useful in some cases to escape local minima.\n",
    "- Sometimes, and depending on your computational resources, this is the only option.\n",
    "\n",
    "__Big batch size__\n",
    "- If your batch size is big enough, this will provide a stable enough estimate of what the gradient of the full dataset would be, since you will have fewer gradient updates per epoch.\n",
    "- In the same logic, it is desired to speed up computation, due to a lower quantity of updates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 26`__ - Create an instance of MLPClassifier, define the batch_size as __5__ and name it as __model_batch5__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch5 = MLPClassifier(solver = 'sgd', batch_size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 27`__ - Create an instance of MLPClassifier, define the batch_size as __50__ and name it as __model_batch50__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch50 = MLPClassifier(solver = 'sgd', batch_size = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 28`__ - Create an instance of MLPClassifier, define the batch_size as __500__ and name it as __model_batch500__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch500 = MLPClassifier(solver = 'sgd', batch_size = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 29`__ - Check the mean accuracy of each model by calling the function _show_results_ and pass as arguments the dataset and the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>batch 5</th>\n",
       "      <td>3.21+/-0.84</td>\n",
       "      <td>0.681+/-0.01</td>\n",
       "      <td>0.672+/-0.08</td>\n",
       "      <td>33.7+/-8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch 50</th>\n",
       "      <td>0.812+/-0.33</td>\n",
       "      <td>0.739+/-0.01</td>\n",
       "      <td>0.714+/-0.06</td>\n",
       "      <td>52.7+/-18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch 500</th>\n",
       "      <td>0.556+/-0.15</td>\n",
       "      <td>0.718+/-0.02</td>\n",
       "      <td>0.68+/-0.03</td>\n",
       "      <td>85.6+/-24.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Time         Train    Validation   Iterations\n",
       "batch 5     3.21+/-0.84  0.681+/-0.01  0.672+/-0.08   33.7+/-8.6\n",
       "batch 50   0.812+/-0.33  0.739+/-0.01  0.714+/-0.06  52.7+/-18.6\n",
       "batch 500  0.556+/-0.15  0.718+/-0.02   0.68+/-0.03  85.6+/-24.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'Iterations'], index = ['batch 5','batch 50','batch 500'])\n",
    "show_results(df, model_batch5, model_batch50, model_batch500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"max_iter\">\n",
    "\n",
    "### 2.7. The maximum iterations (default = 200)\n",
    "</a>\n",
    "\n",
    "By default, sklearn defines the maximum number of iterations as 200. While this could be enough for simple datasets, in complex problems you should try values higher that allow the model to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 30`__ - Create an instance of MLPClassifier, define the max_iter as __20__ and name it as __model_maxiter_20__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_maxiter_20 = MLPClassifier(max_iter = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 31`__ - Create an instance of MLPClassifier, define the max_iter as __100__ and name it as __model_maxiter_100__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_maxiter_100 = MLPClassifier(max_iter = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 32`__ - Create an instance of MLPClassifier, define the max_iter as __500__ and name it as __model_maxiter_500__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_maxiter_500 = MLPClassifier(max_iter = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 33`__ - Check the mean accuracy of each model by calling the function _show_results_ and pass as arguments the dataset and the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max iter 20</th>\n",
       "      <td>0.164+/-0.01</td>\n",
       "      <td>0.676+/-0.03</td>\n",
       "      <td>0.654+/-0.05</td>\n",
       "      <td>20.0+/-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max iter 100</th>\n",
       "      <td>0.74+/-0.2</td>\n",
       "      <td>0.726+/-0.02</td>\n",
       "      <td>0.669+/-0.06</td>\n",
       "      <td>83.5+/-18.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max iter 500</th>\n",
       "      <td>0.951+/-0.35</td>\n",
       "      <td>0.753+/-0.02</td>\n",
       "      <td>0.704+/-0.05</td>\n",
       "      <td>106.9+/-36.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Time         Train    Validation    Iterations\n",
       "max iter 20   0.164+/-0.01  0.676+/-0.03  0.654+/-0.05    20.0+/-0.0\n",
       "max iter 100    0.74+/-0.2  0.726+/-0.02  0.669+/-0.06   83.5+/-18.4\n",
       "max iter 500  0.951+/-0.35  0.753+/-0.02  0.704+/-0.05  106.9+/-36.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Validation', 'Iterations'], index = ['max iter 20','max iter 100','max iter 500'])\n",
    "show_results(df, model_maxiter_20, model_maxiter_100, model_maxiter_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a class=\"anchor\" id=\"other\">\n",
    "\n",
    "### 2.8. Other parameters\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Parameter| Definition | LBFGS | SGD | ADAM |\n",
    "|---|---|---|---|---|\n",
    "|alpha| L2 penalty (regularization term) parameter | yes | yes | yes |\n",
    "| power_t | The exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to ‘invscaling’. | no | yes | no |\n",
    "| shuffle | Whether to shuffle samples in each iteration. | no | yes | yes |\n",
    "| tol | Tolerance for the optimization. When the loss or score is not improving by at least tol for n_iter_no_change consecutive iterations, unless learning_rate is set to ‘adaptive’, convergence is considered to be reached and training stops. | yes | yes | yes |\n",
    "| warm_start | When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. | yes | yes | yes |\n",
    "| momentum | Momentum for gradient descent update. Should be between 0 and 1. | no | yes | no |\n",
    "| nesterovs_momentum | Whether to use Nesterov’s momentum.| no | yes | no |\n",
    "| early stopping | Whether to use early stopping to terminate training when validation score is not improving. If set to true, it will automatically set aside 10% of training data as validation and terminate training when validation score is not improving by at least tol for n_iter_no_change consecutive epochs. The split is stratified, except in a multilabel setting.  | no | yes | yes |\n",
    "| validation_fraction | The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if early_stopping is True | no | yes | yes|\n",
    "| beta1 | Exponential decay rate for estimates of first moment vector in adam, should be in [0, 1). | no | no | yes |\n",
    "| beta2 | Exponential decay rate for estimates of second moment vector in adam, should be in [0, 1).  | no | no | yes |\n",
    "| epsilon | Value for numerical stability in adam. | no | no | yes |\n",
    "| n_iter_no_change | Maximum number of epochs to not meet tol improvement. |  no | yes | yes |\n",
    "| max_fun | Only used when solver=’lbfgs’. Maximum number of loss function calls. The solver iterates until convergence (determined by ‘tol’), number of iterations reaches max_iter, or this number of loss function calls. | yes | no | no |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Grid Search <a class=\"anchor\" id=\"gridsearch\"></a>\n",
    "[Back to Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 34`__ - From sklearn.model_selection import __GridSearchCV__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 35`__ - Define a dictionary named as __parameter_space__ and define the following options to be considered during modelling:\n",
    "- 'hidden_layer_sizes': [(50,50,50), (100,)\n",
    "- 'activation': ['tanh', 'relu']\n",
    "- 'solver': ['sgd', 'adam']\n",
    "- 'learning_rate_init' : [0.0001, 0.001, 0.01, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (100,),(75,75)],\n",
    "    'activation': ['logistic','tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate_init': [0.0001, 0.001, 0.01, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 36`__ - Create an instance of GridSearchCV named as __clf__ and pass as parameters the __model__ and the __parameter_space__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(model, parameter_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 37`__ - Fit your Grid Search to __X_train__ and __y_train__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 37.1__ - By using the method `train_test_split` from `sklearn.model_selection`, split your dataset into train(70%) and validation(30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 150, shuffle = True, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 37.2__ - Fit your instance to __X_train__ and __y_train__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MLPClassifier(),\n",
       "             param_grid={'activation': ['tanh', 'relu'],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50), (100,)],\n",
       "                         'learning_rate_init': [0.0001, 0.001, 0.01, 0.1],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 38`__ - Call the attribute __best_params___ to check which is the best combination of parameters. Create a final model with those parameters by calling the attribute __best_estimator___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'hidden_layer_sizes': (50, 50, 50),\n",
       " 'learning_rate_init': 0.01,\n",
       " 'solver': 'adam'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7746741154562383\n",
      "Test: 0.70995670995671\n"
     ]
    }
   ],
   "source": [
    "final_model = clf.best_estimator_.fit(X_train, y_train)\n",
    "print('Train:', final_model.score(X_train, y_train))\n",
    "print('Test:', final_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 39`__ - Create a loop to check the mean and the standard deviation of the different models created using the different combinations using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Best parameters found:\n",
      " {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "0.656 (+/-0.010) for {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.665 (+/-0.030) for {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.672 (+/-0.048) for {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.672 (+/-0.012) for {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.676 (+/-0.011) for {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "0.650 (+/-0.024) for {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "0.646 (+/-0.006) for {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.1, 'solver': 'sgd'}\n",
      "0.652 (+/-0.003) for {'activation': 'tanh', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.1, 'solver': 'adam'}\n",
      "0.665 (+/-0.022) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.661 (+/-0.021) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.667 (+/-0.019) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.700 (+/-0.018) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.650 (+/-0.021) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "0.700 (+/-0.037) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "0.488 (+/-0.137) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1, 'solver': 'sgd'}\n",
      "0.584 (+/-0.120) for {'activation': 'tanh', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1, 'solver': 'adam'}\n",
      "0.656 (+/-0.041) for {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.668 (+/-0.042) for {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.678 (+/-0.011) for {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.687 (+/-0.025) for {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.667 (+/-0.036) for {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "0.723 (+/-0.030) for {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "0.652 (+/-0.003) for {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.1, 'solver': 'sgd'}\n",
      "0.646 (+/-0.010) for {'activation': 'relu', 'hidden_layer_sizes': (50, 50, 50), 'learning_rate_init': 0.1, 'solver': 'adam'}\n",
      "0.648 (+/-0.050) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.0001, 'solver': 'sgd'}\n",
      "0.656 (+/-0.017) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.0001, 'solver': 'adam'}\n",
      "0.667 (+/-0.030) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001, 'solver': 'sgd'}\n",
      "0.687 (+/-0.045) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001, 'solver': 'adam'}\n",
      "0.605 (+/-0.054) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'sgd'}\n",
      "0.579 (+/-0.040) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01, 'solver': 'adam'}\n",
      "0.650 (+/-0.006) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1, 'solver': 'sgd'}\n",
      "0.656 (+/-0.009) for {'activation': 'relu', 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# Best parameter set\n",
    "print('------------------------------------------------------------------------------------------------------------------------')\n",
    "print('Best parameters found:\\n', clf.best_params_)\n",
    "print('------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# All results\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std , params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
