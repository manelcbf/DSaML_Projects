{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=\"6\">Predictive Project Example</font></b><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/semma.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#BFD72F'>Contents</font> <a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "* [1. Import the data](#import)\n",
    "* [2. Explore the data](#explore)\n",
    "* [3. Prepare the data](#prepare)\n",
    "    * [3. Feature Engineering](#feateng)\n",
    "    * [4. Feature Selection](#feateng)\n",
    "* [5. Model Assessment](#assess)\n",
    "* [6. Predictions](#pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import the data <a class=\"anchor\" id=\"import\"></a>\n",
    "[Back to Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"2nd-bullet\">\n",
    "\n",
    "### 1.1. Import the needed libraries\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 1`__ Import all the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import RFE\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "# Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Model Assessment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2`__ Import the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>402</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>636</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>416</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>273</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>288</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>340</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>427</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>343</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>28</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>939</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>717 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  \\\n",
       "0           402  70.0  1.0   1       156   245    0        0      143      0   \n",
       "1           636  59.0  0.0   0       174   249    0        1      143      1   \n",
       "2           416   NaN  1.0   2       125   273    0        0      152      0   \n",
       "3           142  61.0  1.0   3       134   234    0        1      145      0   \n",
       "4           288  58.0  0.0   2       120   340    0        1      172      0   \n",
       "..          ...   ...  ...  ..       ...   ...  ...      ...      ...    ...   \n",
       "712         427  57.0  1.0   2       150   168    0        1      174      0   \n",
       "713         343  52.0  1.0   2       172   199    1        1      162      0   \n",
       "714         609   NaN  0.0   0       180   327    0        2      117      1   \n",
       "715          28  56.0  1.0   2       130   256    1        0      142      1   \n",
       "716         939  49.0  0.0   1       134   271    0        1      162      0   \n",
       "\n",
       "     oldpeak  slope  ca  thal  target  \n",
       "0        0.0      2   0     2       1  \n",
       "1        0.0      1   0     2       0  \n",
       "2        0.5      0   1     2       1  \n",
       "3        2.6      1   2     2       0  \n",
       "4        0.0      2   0     2       1  \n",
       "..       ...    ...  ..   ...     ...  \n",
       "712      1.6      2   0     2       1  \n",
       "713      0.5      2   0     3       1  \n",
       "714      3.4      1   0     2       0  \n",
       "715      0.6      1   1     1       0  \n",
       "716      0.0      1   0     2       1  \n",
       "\n",
       "[717 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data/heart.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__GOAL__: predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.\n",
    "\n",
    "`age` patient's age in years<br>\n",
    "`sex` patient's gender (1 = male; 0 = female)<br>\n",
    "`cp` chest pain type (4 values)<br>\n",
    "`trestbps` resting blood pressure (in mm Hg on admission to the hospital)<br>\n",
    "`chol` serum cholestoral in mg/dl<br>\n",
    "`fbs` fasting blood sugar > 120 mg/dl (1 = true; 0 = false)<br>\n",
    "`restecg` resting electrocardiographic results (values 0,1,2)<br>\n",
    "`thalach` maximum heart rate achieved<br>\n",
    "`exang` exercise induced angina (1 = yes; 0 = no)<br>\n",
    "`oldpeak` ST depression induced by exercise relative to rest<br>\n",
    "`slope` the slope of the peak exercise ST segment<br>\n",
    "`ca` number of major vessels (0-3) colored by flourosopy<br>\n",
    "`thal` 0 = normal; 1 = fixed defect; 2 = reversable defect<br>\n",
    "`target` refers to the presence of heart disease in the patient<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 3`__ - Define the independent variables as __X__ and the dependent variable as __y__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['target'])\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Explore the data <a class=\"anchor\" id=\"explore\"></a>\n",
    "[Back to Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 4`__ Explore and get insights from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 717 entries, 0 to 716\n",
      "Data columns (total 15 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  717 non-null    int64  \n",
      " 1   age         705 non-null    float64\n",
      " 2   sex         713 non-null    float64\n",
      " 3   cp          717 non-null    int64  \n",
      " 4   trestbps    717 non-null    int64  \n",
      " 5   chol        717 non-null    int64  \n",
      " 6   fbs         717 non-null    int64  \n",
      " 7   restecg     717 non-null    int64  \n",
      " 8   thalach     717 non-null    int64  \n",
      " 9   exang       717 non-null    int64  \n",
      " 10  oldpeak     717 non-null    float64\n",
      " 11  slope       717 non-null    int64  \n",
      " 12  ca          717 non-null    int64  \n",
      " 13  thal        717 non-null    int64  \n",
      " 14  target      717 non-null    int64  \n",
      "dtypes: float64(3), int64(12)\n",
      "memory usage: 84.1 KB\n"
     ]
    }
   ],
   "source": [
    "# small exploration on the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 5`__ Separate the numerical from the categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'slope', 'cp']\n",
    "cat_vars = ['restecg', 'ca', 'thal', 'sex', 'fbs', 'exang']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Types for Independent Variables:\n",
    "- __Categorical__ - restecg, ca, thal\n",
    "- __Continuous__ - age, trestbps, chol, thalach, oldpeak, slope\n",
    "- __Binary__ - sex, fbs, exang\n",
    "- __Ordinal__ - cp\n",
    "\n",
    "Missing values:\n",
    "- age (continuous)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prepare the data <a class=\"anchor\" id=\"prepare\"></a>\n",
    "[Back to Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Feature Engineering <a class=\"anchor\" id=\"feateng\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 6`__ Create new variables from the original ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['log_chol'] = np.log(X['chol'])\n",
    "\n",
    "num_vars.append('log_chol')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Feature Selection<a class=\"anchor\" id=\"featsel\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 7`__ Create a function that selects the best features for each split of a StratifiedKFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features(X, y):\n",
    "    skf = StratifiedKFold(n_splits = 3)\n",
    "    counter = 0\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        counter +=1\n",
    "        print('')\n",
    "        print('--------------------------------------------------------')\n",
    "        print('SPLIT ', counter)\n",
    "        print('--------------------------------------------------------')\n",
    "        print('')\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        \n",
    "        # fill missing values (median in numerical data, mode in categorical data)\n",
    "        median_age_train = X_train['age'].median()\n",
    "        X_train['age'].fillna(median_age_train, inplace = True)\n",
    "        X_val['age'].fillna(median_age_train, inplace = True)\n",
    "        mode_sex_train = X_train['sex'].mode()[0]\n",
    "        X_train['sex'].fillna(mode_sex_train, inplace = True)\n",
    "        X_val['sex'].fillna(mode_sex_train, inplace = True)\n",
    "        \n",
    "        # get all numerical variables\n",
    "        X_train_num = X_train[num_vars]\n",
    "        X_val_num = X_val[num_vars]\n",
    "        \n",
    "        # get all categorical variables\n",
    "        X_train_cat = X_train[cat_vars]\n",
    "        X_val_cat = X_val[cat_vars]\n",
    "        \n",
    "        # Apply scaling to numerical data\n",
    "        scaler = MinMaxScaler().fit(X_train_num)\n",
    "        X_train_scaled = pd.DataFrame(scaler.transform(X_train_num), columns = X_train_num.columns, index = X_train_num.index,) # MinMaxScaler in the training data\n",
    "    \n",
    "        \n",
    "        # Check which features to use using RFE\n",
    "        print('')\n",
    "        print('----------------- RFE ----------------------')\n",
    "        model = LogisticRegression()\n",
    "        rfe = RFE(estimator = model, n_features_to_select = 4)\n",
    "        X_rfe = rfe.fit_transform(X = X_train_scaled, y = y_train)\n",
    "        selected_features = pd.Series(rfe.support_, index = X_train_scaled.columns)\n",
    "        print(selected_features)\n",
    "        \n",
    "        # Check which features to use using Chi-Square\n",
    "        print('')\n",
    "        print('----------------- CHI-SQUARE ----------------------')\n",
    "        def TestIndependence(X,y,var,alpha=0.05):        \n",
    "            dfObserved = pd.crosstab(y,X) \n",
    "            chi2, p, dof, expected = stats.chi2_contingency(dfObserved.values)\n",
    "            dfExpected = pd.DataFrame(expected, columns=dfObserved.columns, index = dfObserved.index)\n",
    "            if p<alpha:\n",
    "                result=\"{0} is IMPORTANT for Prediction\".format(var)\n",
    "            else:\n",
    "                result=\"{0} is NOT important for Prediction. (Discard {0} from model)\".format(var)\n",
    "            print(result)\n",
    "        \n",
    "        for var in X_train_cat:\n",
    "            TestIndependence(X_train_cat[var],y_train, var)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------\n",
      "SPLIT  1\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------- RFE ----------------------\n",
      "age         False\n",
      "trestbps     True\n",
      "chol        False\n",
      "thalach      True\n",
      "oldpeak      True\n",
      "slope       False\n",
      "cp           True\n",
      "log_chol    False\n",
      "dtype: bool\n",
      "\n",
      "----------------- CHI-SQUARE ----------------------\n",
      "restecg is IMPORTANT for Prediction\n",
      "ca is IMPORTANT for Prediction\n",
      "thal is IMPORTANT for Prediction\n",
      "sex is IMPORTANT for Prediction\n",
      "fbs is NOT important for Prediction. (Discard fbs from model)\n",
      "exang is IMPORTANT for Prediction\n",
      "\n",
      "--------------------------------------------------------\n",
      "SPLIT  2\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------- RFE ----------------------\n",
      "age         False\n",
      "trestbps    False\n",
      "chol        False\n",
      "thalach      True\n",
      "oldpeak      True\n",
      "slope        True\n",
      "cp           True\n",
      "log_chol    False\n",
      "dtype: bool\n",
      "\n",
      "----------------- CHI-SQUARE ----------------------\n",
      "restecg is IMPORTANT for Prediction\n",
      "ca is IMPORTANT for Prediction\n",
      "thal is IMPORTANT for Prediction\n",
      "sex is IMPORTANT for Prediction\n",
      "fbs is NOT important for Prediction. (Discard fbs from model)\n",
      "exang is IMPORTANT for Prediction\n",
      "\n",
      "--------------------------------------------------------\n",
      "SPLIT  3\n",
      "--------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------- RFE ----------------------\n",
      "age         False\n",
      "trestbps     True\n",
      "chol        False\n",
      "thalach      True\n",
      "oldpeak      True\n",
      "slope       False\n",
      "cp           True\n",
      "log_chol    False\n",
      "dtype: bool\n",
      "\n",
      "----------------- CHI-SQUARE ----------------------\n",
      "restecg is IMPORTANT for Prediction\n",
      "ca is IMPORTANT for Prediction\n",
      "thal is IMPORTANT for Prediction\n",
      "sex is IMPORTANT for Prediction\n",
      "fbs is NOT important for Prediction. (Discard fbs from model)\n",
      "exang is IMPORTANT for Prediction\n"
     ]
    }
   ],
   "source": [
    "select_best_features(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the previous results:\n",
    "- Using RFE (selecting the 4 more important features):\n",
    "    - thalach is always important (keep the variable)\n",
    "    - oldpeak is always important (keep the variable)\n",
    "    - cp is always important (keep the variable)\n",
    "    - trestbps is important twice (keep the variable)\n",
    "    - slope is important only once (remove the variable)\n",
    "\n",
    "\n",
    "- Using Chi-Square:\n",
    "    - fbs is never important (remove the variable)\n",
    "\n",
    "    \n",
    "Concluding, we should keep the variables (this is a possible interpretation):\n",
    "    - thalach, oldpeak, cp, trestbps, restecg, ca, thal, sex and exang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 8`__ Choose the best variables to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>restecg</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>sex</th>\n",
       "      <th>exang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>174</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>162</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>117</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>142</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>162</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>717 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     thalach  oldpeak  cp  trestbps  restecg  ca  thal  sex  exang\n",
       "0        143      0.0   1       156        0   0     2  1.0      0\n",
       "1        143      0.0   0       174        1   0     2  0.0      1\n",
       "2        152      0.5   2       125        0   1     2  1.0      0\n",
       "3        145      2.6   3       134        1   2     2  1.0      0\n",
       "4        172      0.0   2       120        1   0     2  0.0      0\n",
       "..       ...      ...  ..       ...      ...  ..   ...  ...    ...\n",
       "712      174      1.6   2       150        1   0     2  1.0      0\n",
       "713      162      0.5   2       172        1   0     3  1.0      0\n",
       "714      117      3.4   0       180        2   0     2  0.0      1\n",
       "715      142      0.6   2       130        0   1     1  1.0      1\n",
       "716      162      0.0   1       134        1   0     2  0.0      0\n",
       "\n",
       "[717 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_vars = ['thalach','oldpeak','cp','trestbps','restecg','ca','thal','sex','exang']\n",
    "\n",
    "# select the final features \n",
    "X_sel = X[best_vars].copy()\n",
    "X_sel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Assessment<a class=\"anchor\" id=\"assess\"></a>\n",
    "[Back to Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 9`__ Create a function that compares several models using F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(X, y, model):\n",
    "    # apply StratifiedK-Fold\n",
    "    skf = StratifiedKFold(n_splits = 5)\n",
    "    score_train = []\n",
    "    score_val = []\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        # This time we are going to use validation to check overfitting \n",
    "        # so we need also to make all the needed changes in the validation\n",
    "        \n",
    "        # fill missing values (mean in numerical data, mode in categorical data)\n",
    "        #median_age_train = X_train['age'].median() # age is no longer used\n",
    "        #X_train['age'].fillna(median_age_train, inplace = True)\n",
    "        #X_val['age'].fillna(median_age_train, inplace = True)\n",
    "        mode_sex_train = X_train['sex'].mode()[0]\n",
    "        X_train['sex'].fillna(mode_sex_train, inplace = True)\n",
    "        X_val['sex'].fillna(mode_sex_train, inplace = True)\n",
    "        \n",
    "        # Create dummies and remove one of the variables (to avoid multicollinearity)\n",
    "        X_train_dummies = pd.get_dummies(X_train, columns=['restecg', 'ca', 'thal'], drop_first=True)\n",
    "        X_val_dummies = pd.get_dummies(X_val, columns=['restecg', 'ca', 'thal'], drop_first=True)\n",
    "        \n",
    "        # If we don't have all the values in the validation dataset that we have in the train, that column will not be created\n",
    "        # We should assure that all columns in train are also present in validation\n",
    "        # Get missing columns from the training dataset\n",
    "        missing_cols = set(X_train_dummies.columns ) - set(X_val_dummies.columns )\n",
    "        # Add a missing column in test set with default value equal to 0\n",
    "        for c in missing_cols:\n",
    "            X_val_dummies[c] = 0\n",
    "        # Ensure the order of column in the test set is in the same order than in train set\n",
    "        X_val_dummies = X_val_dummies[X_train_dummies.columns]\n",
    "        \n",
    "        # Data Scaling\n",
    "        # Apply MinMaxScaler\n",
    "        scaler = MinMaxScaler().fit(X_train_dummies)\n",
    "        X_train_scaled = scaler.transform(X_train_dummies) \n",
    "        X_val_scaled = scaler.transform(X_val_dummies) # Scaling with 'scaler' from train data\n",
    "\n",
    "        # Apply model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        predictions_train = model.predict(X_train_scaled)\n",
    "        predictions_val = model.predict(X_val_scaled)\n",
    "        score_train.append(f1_score(y_train, predictions_train))\n",
    "        score_val.append(f1_score(y_val, predictions_val))\n",
    "\n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_val = round(np.mean(score_val),3)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_val = round(np.std(score_val),2)\n",
    "\n",
    "    return str(avg_train) + '+/-' + str(std_train),str(avg_val) + '+/-' + str(std_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(df, X, y, *args):\n",
    "    \"\"\"\n",
    "    Receive an empty dataframe and the different models and call the function avg_score\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # for each model passed as argument\n",
    "    for arg in args:\n",
    "        # obtain the results provided by avg_score\n",
    "        avg_train, avg_test = compare_models(X, y, arg)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = avg_train, avg_test\n",
    "        count+=1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 10`__ Compare the results of a Logistic Regression with a K-Nearest-Neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.876+/-0.01</td>\n",
       "      <td>0.869+/-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.922+/-0.0</td>\n",
       "      <td>0.865+/-0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Train    Validation\n",
       "Logistic Regression  0.876+/-0.01  0.869+/-0.01\n",
       "KNN                   0.922+/-0.0  0.865+/-0.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR = LogisticRegression()\n",
    "model_KNN = KNeighborsClassifier()\n",
    "\n",
    "df = pd.DataFrame(columns = ['Train','Validation'], index = ['Logistic Regression','KNN'])\n",
    "show_results(df, X_sel, y, model_LR, model_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the results, the best model is Logistic Regression with the default parameters since it performs better on validation and has a lower value of **overfitting**.  <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predictions<a class=\"anchor\" id=\"pred\"></a>\n",
    "[Back to Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to create our final model using all the training data (the more data the better and this model should have exactly the same structure than the selected model on the previous phase, i.e., a KNN with the default parameters.) <br><br>\n",
    "Then we need to import the test dataset, made all the needed transformations and finally export the csv with the predictions (final answers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 11`__ Create the final model and train it with the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = X[best_vars].copy()\n",
    "y_final = y.copy()\n",
    "\n",
    "#median_age = X_final['age'].median()\n",
    "#X_final['age'].fillna(median_age, inplace = True)\n",
    "mode_sex = X_final['sex'].mode()[0]\n",
    "X_final['sex'].fillna(mode_sex, inplace = True)\n",
    "        \n",
    "# Create dummies and remove one of the variables (to avoid multicollinearity)\n",
    "X_final_dummies = pd.get_dummies(X_final, columns=['restecg', 'ca', 'thal'], drop_first=True)\n",
    "\n",
    "\n",
    "# Data Scaling\n",
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X_final_dummies)\n",
    "X_final_scaled = scaler.transform(X_final_dummies) \n",
    "\n",
    "# Create your final model with exactly the same parameters than your best model during model comparison\n",
    "final_model = KNeighborsClassifier().fit(X_final_scaled, y_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 12`__ Apply the final created model to get the predictions of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('data/heart_score.xlsx')\n",
    "\n",
    "test_final = test[best_vars].copy()\n",
    "#test_final['age'].fillna(median_age, inplace = True)\n",
    "test_final['sex'].fillna(mode_sex, inplace = True)\n",
    "        \n",
    "# Create dummies and remove one of the variables (to avoid multicollinearity)\n",
    "test_final_dummies = pd.get_dummies(test_final, columns=['restecg', 'ca', 'thal'], drop_first=True)\n",
    "\n",
    "# If we don't have all the values in the test dataset that we have in the train, that column will not be created\n",
    "# We should assure that all columns in train are also present in test\n",
    "# Get missing columns from the training dataset\n",
    "missing_cols = set(X_final_dummies.columns ) - set(test_final_dummies.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    test_final_dummies[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "test_final_dummies = test_final_dummies[X_final_dummies.columns]\n",
    "\n",
    "# Data Scaling\n",
    "# Apply exactly the same MinMaxScaler used before\n",
    "test_final_scaled = scaler.transform(test_final_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 13`__ Get the final predictions made by the final model. Create a dataframe with the needed columns for your final delivery: 'ID' that will contain the ID of the pations and 'Answer', the predicted value for each patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Answer\n",
       "0      0       1\n",
       "1      1       1\n",
       "2      2       1\n",
       "3      3       1\n",
       "4      4       1\n",
       "..   ...     ...\n",
       "303  303       1\n",
       "304  304       0\n",
       "305  305       0\n",
       "306  306       0\n",
       "307  307       0\n",
       "\n",
       "[308 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions\n",
    "predictions = final_model.predict(test_final_scaled)\n",
    "\n",
    "# Save the final predictions\n",
    "patient_index = test.index.T\n",
    "answer = pd.DataFrame([patient_index, predictions]).T\n",
    "answer.columns = ['ID','Answer']\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 14`__ Save that dataframe into a csv file named as 'answer.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer.to_csv('answer.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
