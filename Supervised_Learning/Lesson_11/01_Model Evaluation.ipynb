{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><font size=\"6\">01. Model Evaluation</font></b><br><br>\n",
    "We can define **Model Evaluation** as the process of measuring how well the model is performing a certain task. This evaluation is done by checking the performance of one or more different predictive models based on the use of a validation, or test dataset.\n",
    "<br>\n",
    "# <font color='#BFD72F'>Contents</font> <a class=\"anchor\" id=\"toc\"></a>\n",
    "\n",
    "* [0 - Import Libraries and Data](#import)<br>\n",
    "* [1 - Data Partition Techniques](#datapart)<br>\n",
    "    * [1.1. The Hold-Out Method](#1st-bullet)<br>\n",
    "    * [1.2. The K-Fold Cross Validation](#2nd-bullet)<br>\n",
    "    * [1.3. The leave One Out](#4th-bullet)<br>\n",
    "    * [1.4. Stratified k-fold and others](#5th-bullet)<br>\n",
    "* [2 - Compare Models](#train-test)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#BFD72F'> Supervised versus Unsupervised Methods</font>\n",
    "<font size=\"1\">Daniel T. Larose, Chantal D. Larose (2015) “Data Mining and Predictive Analytics,” 2nd Edition, Wiley (pp. 160-161)</font>\n",
    "\n",
    "Data mining methods may be categorized as either supervised or unsupervised. In **unsupervised methods**, no target variable is identified as such. Instead, the data mining algorithm searches for patterns and structures among all the variables. The most common unsupervised data mining method is clustering.\n",
    "\n",
    "Most data mining methods are **supervised methods**, however, meaning that there is a particular prespecified target variable, and that the algorithm is given many examples where the value of the target variable is provided, so that the algorithm may learn which values of the target variable are associated with which values of the predictor variables. For example, regression methods are supervised methods.\n",
    "\n",
    "<img src=\"images\\sup_unsup.png\" width=\"600px\">\n",
    "\n",
    "If you wish to explore this difference further, check this <a href=\"https://www.ibm.com/cloud/blog/supervised-vs-unsupervised-learning\"> link</a>.\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\semma.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importing Libraries and Data <a class=\"anchor\" id=\"import\"></a>\n",
    "[Back to Contents](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 1`__ Import the needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 2`__ Read the dataset __diabetes.csv__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv(r'data/diabetes.csv')\n",
    "diabetes.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### `Diabetes dataset`\n",
    "(Source: UCI Machine Learning Repository)\n",
    "\n",
    "`INPUT VARIABLES`: numeric <br>\n",
    "`OUPUT VARIABLE`: categorical <br>\n",
    "\n",
    "__GOAL__: predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset.\n",
    "\n",
    "`Pregnancies` Number of times pregnant <br>\n",
    "`Glucose` Plasma glucose concentration a 2 hours in an oral glucose tolerance test<br>\n",
    "`BloodPressure`Diastolic blood pressure (mm Hg)<br>\n",
    "`SkinThickness`Triceps skin fold thickness (mm)<br>\n",
    "`Insulin`2-Hour serum insulin (mu U/ml)<br>\n",
    "`BMI` Body mass index (weight in kg/(height in m)^2)<br>\n",
    "`DiabetesPedigreeFunction` Diabetes pedigree function<br>\n",
    "`Age`Age (years)<br>\n",
    "`Outcome` Class variable (0 or 1) 268 of 768 are 1, the others are 0<br>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 3`__ Create an object named __data__ that will contain your independent variables and another object named __target__ that will contain your dependent variable / target (the last column in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = diabetes.iloc[:,:-1]\n",
    "target = diabetes.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data partition <a class=\"anchor\" id=\"datapart\"></a>\n",
    "[Back to Contents](#toc)\n",
    "<br><br>\n",
    "* [1.1. The Hold-Out Method](#1st-bullet)<br>\n",
    "* [1.2. The K-Fold Cross Validation](#2nd-bullet)<br>\n",
    "* [1.3. The leave One Out](#4th-bullet)<br>\n",
    "* [1.4. Stratified k-fold and others](#5th-bullet)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"1st-bullet\">\n",
    "\n",
    "## 1.1. The Hold-Out Method\n",
    "    \n",
    "</a>\n",
    "\n",
    "In this approach we randomly split the complete data into **training** and **test** sets. Then perform the model training on the training set and use the test set for validation purpose, ideally split the data into 70:30 or 80:20. With this approach there is a possibility of high bias if we have limited data, because we would miss some information about the data which we have not used for training. If our data is huge and our test sample and train sample has the same distribution then this approach is acceptable. <br>\n",
    "\n",
    "<img src=\"images/hold_out.jpg\" width=\"400px\" />\n",
    "\n",
    "By default, `sklearn` has a function named `train_test_split` that allows to split the dataset into two different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 4`__ Import the library `train_test_split` from `sklearn.model_selection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 5`__ Divide the `data`into `X_train_val` and `X_test`, the `target`into `y_train_val` and `y_test`, and define the following arguments: `test_size = 0.2`, `random_state = 15`, `shuffle = True` and `stratify = target`  _(written for you)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(data, \n",
    "                                                    target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=15, \n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=target\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will allow me to create two different datasets, one for train (80% of the data) and one for test (20% of the data). <br>\n",
    "The stratification will allow me to have the same proportion of each label of the dependent variable in both datasets.\n",
    "\n",
    "\n",
    "### How to create the three datasets: train, validation and test?\n",
    "\n",
    "In this exercise, we are going to split our dataset into **train**, **test** and **validation**. <br> <br>\n",
    "\n",
    "<img src=\"images/hold_out_3.png\" width=500 />\n",
    "\n",
    "To create three datasets (train, validation and test) we are going to use the function train_test_split twice. <br><br>\n",
    "First we are going to create two sets of datasets, one for test (X_test and y_test) and another one that includes the data for training and validation (X_train_val and y_train_val).\n",
    "\n",
    "__`Step 6`__  Divide the `X_train_val`into `X_train` and `X_val`, the `y_train_val` into `y_train` and `y_val`, and define the following arguments: `test_size = 0.25`, `random_state = 15`, `shuffle = True` and `stratify = y_train_val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val,\n",
    "                                                  y_train_val,\n",
    "                                                  test_size = 0.25,\n",
    "                                                  random_state = 15,\n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y_train_val\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 7`__ Check the proportion of data for each dataset. _(written for you)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:0.6% | validation:0.2% | test:0.2%\n"
     ]
    }
   ],
   "source": [
    "print('train:{}% | validation:{}% | test:{}%'.format(round(len(y_train)/len(target),2),\n",
    "                                                     round(len(y_val)/len(target),2),\n",
    "                                                     round(len(y_test)/len(target),2)\n",
    "                                                    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have three different datasets, namely:\n",
    "- Training dataset, with 60% of the data, that will allow me to build the model;\n",
    "- Validation dataset, with 20% of the data, that will allow me to fine tune the model and check some problems like overfitting;\n",
    "- Test dataset, with 20% of the data, that will allow me to evaluate the performance of the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 8`__ Now we are going to train and validate a model (Logictic Regression) using the created datasets. Start by importing __LogisticRegression__ from __sklearn.linear_model__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 9`__ Create an instance of `LogisticRegression` named as __log_model__ with the default parameters and `fit` to your train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 10`__ Check the performance of your model using the method `.score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7934782608695652\n",
      "Validation: 0.7597402597402597\n",
      "Test: 0.7597402597402597\n"
     ]
    }
   ],
   "source": [
    "print('Train:', log_model.score(X_train, y_train))\n",
    "print('Validation:', log_model.score(X_val, y_val))\n",
    "print('Test:', log_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a class=\"anchor\" id=\"2nd-bullet\">\n",
    "\n",
    "## 1.2. K-Fold Cross-Validation\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different techniques we are going to check in this step are commonly used in applied machine learning to compare and select a model for a given predictive modeling problem.\n",
    "\n",
    "__Definition__<br>\n",
    "_Divide the total dataset into k subsets mutually exclusive of the same size. Each subset is going to be used as test and the remaining k-1 subsets will be used for training. This process is repeated k times by alternating the test subset._\n",
    "\n",
    "<img src=\"images/kfold.png\" width=400 />\n",
    "\n",
    "In the following cases, we are going to check the performance of a Logistic Regression using those different techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 11`__ Import __KFold__ from __sklearn.model_selection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__`Step 12`__ Create a function named __avg_score__ that will return the average score value for the train and the test set by applying a model, in this case, Logistic Regression. This will have as parameters the technique you are going to use, the model, your dependent variable and your independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score(method, mod, X, y):\n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    \n",
    "    for train_index, test_index in method.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        model = mod.fit(X_train, y_train)\n",
    "        value_train = model.score(X_train,y_train)\n",
    "        print('Train:', value_train)\n",
    "        value_test = model.score(X_test, y_test)\n",
    "        print('Test:', value_test)\n",
    "        print('')\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "\n",
    "    print('-------------------------------')\n",
    "    print('Average Train:' +  str(round(np.mean(score_train),4)) + '+/-' + str(round(np.std(score_train),4)))\n",
    "    print('Average Test:' +  str(round(np.mean(score_test),4)) + '+/-' + str(round(np.std(score_test),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 13`__ Create a KFold Instance where the number of splits is 10 (*n_splits*) and name it as __kf__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 14`__ Call the function __avg_score__ and check the average score for the train and the test sets using __kf__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7988422575976846\n",
      "Test: 0.7012987012987013\n",
      "\n",
      "Train: 0.7742402315484804\n",
      "Test: 0.8441558441558441\n",
      "\n",
      "Train: 0.7785817655571635\n",
      "Test: 0.7532467532467533\n",
      "\n",
      "Train: 0.788712011577424\n",
      "Test: 0.6883116883116883\n",
      "\n",
      "Train: 0.7829232995658466\n",
      "Test: 0.7922077922077922\n",
      "\n",
      "Train: 0.7901591895803184\n",
      "Test: 0.7402597402597403\n",
      "\n",
      "Train: 0.768451519536903\n",
      "Test: 0.8571428571428571\n",
      "\n",
      "Train: 0.7742402315484804\n",
      "Test: 0.8181818181818182\n",
      "\n",
      "Train: 0.7933526011560693\n",
      "Test: 0.7368421052631579\n",
      "\n",
      "Train: 0.7803468208092486\n",
      "Test: 0.8026315789473685\n",
      "\n",
      "-------------------------------\n",
      "Average Train:0.783+/-0.0091\n",
      "Average Test:0.7734+/-0.0552\n"
     ]
    }
   ],
   "source": [
    "avg_score(kf, LogisticRegression(), data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"4th-bullet\">\n",
    "\n",
    "## 1.4. Leave One Out\n",
    "    \n",
    "</a>\n",
    "\n",
    "__Definition__<br>\n",
    "_We divide the data set into two parts. In one part we have a single observation, which is our test data and in the other part, we have all the other observations from the dataset forming our training data.\n",
    "If we have a data set with n observations then training data contains n-1 observation and test data contains 1 observation._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 15`__ Do the same steps you applied on the previous techniques, but this time using the Leave One Out. For that, you need to import __LeaveOneOut__ from __sklearn.model_selection__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.788787483702738\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7731421121251629\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.788787483702738\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7731421121251629\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7900912646675359\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.788787483702738\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.788787483702738\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7900912646675359\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7744458930899609\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7731421121251629\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7861799217731421\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.78748370273794\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7848761408083442\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.788787483702738\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7783572359843546\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7835723598435462\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7757496740547588\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7770534550195567\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7822685788787483\n",
      "Test: 1.0\n",
      "\n",
      "Train: 0.7796610169491526\n",
      "Test: 0.0\n",
      "\n",
      "Train: 0.7809647979139505\n",
      "Test: 1.0\n",
      "\n",
      "-------------------------------\n",
      "Average Train:0.7817+/-0.0026\n",
      "Average Test:0.7786+/-0.4152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "avg_score(loo, LogisticRegression(), data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"5th-bullet\">\n",
    "\n",
    "## 1.5. Stratified k-fold and others\n",
    "    \n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SkLearn you have several options to select your model, and the application is similar to the cases we saw previously.\n",
    "\n",
    "<img src=\"images/model_selection.png\" alt=\"Drawing\" style=\"width: 800px;\"/> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"6th-bullet\">\n",
    "\n",
    "## 1.6. Comparing models\n",
    "    \n",
    "</a>\n",
    "\n",
    "Don't forget that the purpose of this notebook is to compare different models. In this step, you are going to fit your data into a DecisionTree model also, and use the __RepeatedKFold__ to compare the performance of it with the Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 16`__ Import __DecisionTreeClassifier__ from __sklearn.tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`Step 17`__ Similarly to step 12, use the function named __avg_score__ that will return the average score value for the train and the test set, but this time check the results for a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.8422575976845152\n",
      "Test: 0.6493506493506493\n",
      "\n",
      "Train: 0.8364688856729378\n",
      "Test: 0.7792207792207793\n",
      "\n",
      "Train: 0.8263386396526773\n",
      "Test: 0.7012987012987013\n",
      "\n",
      "Train: 0.8480463096960926\n",
      "Test: 0.5844155844155844\n",
      "\n",
      "Train: 0.8379160636758322\n",
      "Test: 0.8051948051948052\n",
      "\n",
      "Train: 0.8364688856729378\n",
      "Test: 0.8311688311688312\n",
      "\n",
      "Train: 0.8306801736613604\n",
      "Test: 0.8311688311688312\n",
      "\n",
      "Train: 0.8335745296671491\n",
      "Test: 0.8311688311688312\n",
      "\n",
      "Train: 0.8395953757225434\n",
      "Test: 0.7105263157894737\n",
      "\n",
      "Train: 0.8236994219653179\n",
      "Test: 0.7631578947368421\n",
      "\n",
      "-------------------------------\n",
      "Average Train:0.8355+/-0.0069\n",
      "Average Test:0.7487+/-0.0808\n"
     ]
    }
   ],
   "source": [
    "avg_score(KFold(n_splits=10), DecisionTreeClassifier(max_depth = 5), data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the decision trees are prone to overfitting. In the notebook 4, we are going to address some techniques to reduce this overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
